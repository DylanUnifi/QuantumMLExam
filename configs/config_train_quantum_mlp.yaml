experiment_name: "quantum_mlp_mnist"

dataset:
  name: "fashion_mnist"
  selected_classes: [3, 8]

training:
  batch_size: 64
  epochs: 30
  learning_rate: 0.001
  kfold: 5
  early_stopping: 7
  scheduler: "step"  # options: None, step, cosine, etc.

model:
  input_size: 784  # 28x28 flattened Fashion_MNIST
  hidden_sizes: [256, 128, 64]  # optional if tu veux les customiser

checkpoint:
  save_dir: "checkpoints"
  subdir: "quantum_mlp"
