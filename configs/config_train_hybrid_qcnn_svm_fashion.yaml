experiment_name: "hybrid_qcnn_svm_fashion_exp"

dataset:
  name: "fashion_mnist"       # Dataset: fashionmnist, mnist, svhn, etc.
  binary_classes: [3, 8]     # Classes à utiliser pour la classification binaire

training:
  batch_size: 64
  epochs: 20                # Nombre d'époques pour l'entraînement du feature extractor
  learning_rate: 0.0005      # LR initial pour Adam
  kfold: 3                   # Nombre de splits pour KFold cross-validation
  early_stopping: 10          # Patience d'early stopping
  scheduler: "StepLR"          # Options: null, StepLR, MultiStepLR, CosineAnnealingLR
  scheduler_params:
    step_size: 10              # Applicable à StepLR
    gamma: 0.5                 # Facteur de réduction du LR

svm:
  optimize: false            # Pour ce script, on désactive Optuna (support non inclus ici)
  n_trials: 30               # Ignoré si optimize=false
  kernel_options: ["rbf", "poly", "sigmoid"]  # Ignoré si optimize=false
  C_range: [0.001, 1000.0]   # Ignoré si optimize=false
  gamma_range: [0.0001, 10.0] # Ignoré si optimize=false
  default_C: 1.0             # Valeur de C utilisée pour le SVM final
  default_kernel: "rbf"      # Kernel utilisé pour le SVM final
  default_gamma: "scale"     # Gamma utilisé pour le SVM final

quantum:
  n_qubits: 4                # Nombre de qubits dans le circuit quantique
  layers: 2                  # Nombre de couches dans le circuit
  backend: "lightning.qubit" # Backend PennyLane: default.qubit, lightning.qubit, etc.
