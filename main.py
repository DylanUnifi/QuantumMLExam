# main.py
# Version: 6.0 â€“ Ajout d'une intÃ©gration unifiÃ©e avec Weights & Biases (wandb)

import argparse
import numpy as np
import torch
import random
import sys
import wandb  # ðŸŽ‰
from train_hybrid_qcnn_svm import run_train_hybrid_qcnn_svm

from configs.config import load_config
from train_classical import run_train_classical
from train_cnn import run_train_cnn
from train_hybrid_qcnn import run_train_hybrid_qcnn
from train_svm import run_train_svm
from train_quantum_mlp import run_train_quantum_mlp


def set_seed(seed):
    torch.manual_seed(seed)
    np.random.seed(seed)
    random.seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(seed)


def main():
    parser = argparse.ArgumentParser(description="Unified training script for classical, CNN, hybrid QCNN, Quantum MLP,"
                                                 "hybrid_qcnn_svm, SVM, and  models.")
    parser.add_argument("--model", type=str, required=True,
                        help="Model name: classical, cnn, hybrid_qcnn, quantum_mlp, hybrid_qcnn_svm, svm")
    parser.add_argument("--config", type=str, default="configs/config_train_quantum_mlp_fashion.yaml",
                        help="Path to configuration YAML file")
    parser.add_argument("--optimize", action="store_true",
                        help="Enable Optuna hyperparameter optimization (if supported by the model)")
    parser.add_argument("--project", type=str, default="qml_project",
                        help="Weights & Biases project name")

    args = parser.parse_args()
    available_models = {"classical", "cnn", "hybrid_qcnn", "svm", "quantum_mlp", "hybrid_qcnn_svm"}

    if args.model not in available_models:
        print(f"[ERROR] Unsupported model '{args.model}'. Choose from: {', '.join(available_models)}.")
        sys.exit(1)

    print(f"[INFO] Loading config: {args.config}")
    config = load_config(args.config)
    set_seed(config.get("seed", 42))

    print(f"[INFO] Starting training for model: {args.model.upper()}")
    print(f"[INFO] Hyperparameter optimization: {'ENABLED' if args.optimize else 'DISABLED'}")

    # ðŸ”¥ Initialise wandb
    wandb.init(
        project=args.project,
        name=f"{args.model}_{wandb.util.generate_id()}",
        config=config,
        tags=[config["dataset"]["name"], args.model]
    )

    # âž¤ Lancement du bon script en fonction du modÃ¨le choisi
    if args.model == "classical":
        run_train_classical(config)
        wandb.finish()
    elif args.model == "cnn":
        run_train_cnn(config)
        wandb.finish()
    elif args.model == "hybrid_qcnn":
        run_train_hybrid_qcnn(config)
        wandb.finish()
    elif args.model == "quantum_mlp":
        run_train_quantum_mlp(config)
        wandb.finish()
    elif args.model == "hybrid_qcnn_svm":
        run_train_hybrid_qcnn_svm(config)
        wandb.finish()
    elif args.model == "svm":
        config.setdefault("svm", {})
        config["svm"]["optimize"] = args.optimize
        run_train_svm(config)
        wandb.finish()
    else:
        raise ValueError(f"Unsupported model: {args.model}")

    print(f"[INFO] Training for {args.model.upper()} completed successfully.")
    wandb.finish()  # âœ… ClÃ´turer le run proprement


if __name__ == "__main__":
    main()
